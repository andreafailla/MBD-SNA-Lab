{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>\n",
    "<img src=\"img/cdlib_new.png\" width=\"120px\" align=\"right\"/>\n",
    "</span>\n",
    "<span>\n",
    "<b>Authors:</b> <a href=\"http://about.giuliorossetti.net\">Giulio Rossetti</a>, <a href=\"https://andreafailla.github.io/\">Andrea Failla</a><br/>\n",
    "<b>Python version:</b>  3.11<br/>\n",
    "<b>CDlib version:</b>  0.4.0<br/>\n",
    "<b>Last update:</b> 01/07/2025\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cdlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# *Community Discovery*\n",
    "\n",
    "In this notebook are introduced the main steps for the extraction and topological analysis of communities.\n",
    "\n",
    "**Note:** this notebook is purposely not 100% comprehensive, it only discusses the basic things you need to get started. For all the details, algorithm/methods/evaluation facilities available in ``CDlib``, please refer to the official [documentation](https://cdlib.readthedocs.io) and the dedicated notebook appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Community Discovery Workflow](#workflow)\n",
    "    1. [Graph Creation](#graph)\n",
    "    2. [Community Discovery algorithm(s) selection and configuration ](#model)\n",
    "    3. [Clustering Evaluation (Fitness functions)](#fitness)\n",
    "    4. [Clustering Evaluation (Comparison)](#comparison)\n",
    "    5. [Community/Statistics Visualization](#visualization)\n",
    "    5. [Qualitative evaluation](#qualitative)\n",
    "    7. [Ground Truth evaluation](#gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdlib\n",
    "cdlib.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='workflow'></a>\n",
    "## Community Discovery Workflow ([to top](#top))\n",
    "\n",
    "The standard workflow can be summarized as:\n",
    "- Network Creation\n",
    "- Community Discovery algorithm(s) selection and configuration\n",
    "- Clustering(s) evaluation (Fitness functions)\n",
    "- Clustering(s) evaluation (Comparisons)\n",
    "- Community/Statistics Visualization\n",
    "\n",
    "In this section we will observe how to templating such workflow applying two classic network clustering algorithms: Label Propagation and louvain.\n",
    "All analysis will be performed using ``CDlib``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graph\"></a>\n",
    "### Graph object creation ([to top](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we need to define the network topology that will be used as playground to study diffusive phenomena.\n",
    "\n",
    "``CDlib`` natively supports both [``networkx``](https://networkx.github.io) and [``igraph``](https://igraph.org/python/) data structures.\n",
    "\n",
    "In our examples, for the sake of simplicity, we will use ``networkx`` undirected graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "g = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "### Community Discovery algorithm(s) selection and configuration ([to top](#top))\n",
    "\n",
    "After having defined the graph, we can select the algorithm(s) to partition it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_coms = algorithms.label_propagation(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms = algorithms.louvain(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Community Discovery algorithms generate as result an object that implements a concrete instance of the ``Clustering`` datatype.\n",
    "\n",
    "In particular, both Louvain and Label Propagation returns a ``NodeClustering`` object having the following propterties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.method_name # Clustering algorithm name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.method_parameters # Clustering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.communities # Identified Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.overlap # Wehter the clustering is overlapping or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.node_coverage # Percentage of nodes covered by the clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, ``Clustering`` object allow also for the generation of a JSON representation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fitness\"></a>\n",
    "### Clustering Evaluation (Fitness functions) ([to top](#top))\n",
    "\n",
    "After having obtained a network clustering we can compute several indexes upon it. \n",
    "\n",
    "For a same index it is possible to obtain a synthetic representation of its min/max/mean/std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.average_internal_degree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as its communitiy-wise value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.average_internal_degree(summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitness scores can also be instantiated at library level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import evaluation\n",
    "\n",
    "evaluation.average_internal_degree(g, louvain_coms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the complete list of implemented fitness functions, refer to the online [documentation](https://cdlib.readthedocs.io/en/latest/reference/evaluation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a>\n",
    "### Clustering Evaluation (Comparison) ([to top](#top))\n",
    "\n",
    "When multiple clustering have been computed on a same network it is useful to measure their resemblance.\n",
    "\n",
    "``CDlib`` allows to do so by exposing several clustering resemblance scores, each one of them tailored to support specific kind of network clusterings (crisp/partition, complete/partial node coverage).\n",
    "\n",
    "As for the fitness functions, resemblance scores can be instantiated at the community level as well as at the library level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_coms.normalized_mutual_information(lp_coms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.normalized_mutual_information(louvain_coms, lp_coms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualization\"></a>\n",
    "### Community/Statistics Visualization ([to top](#top))\n",
    "\n",
    "``CDlib`` allows to generate two families of predefined plots:\n",
    "- network/community visualizations\n",
    "- community fitness/comparison visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph visualization\n",
    "\n",
    "One way to visualize the communities identified on a graph is by coloring graph nodes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import viz\n",
    "\n",
    "pos = nx.spring_layout(g)\n",
    "viz.plot_network_clusters(g, louvain_coms, pos, figsize=(20, 20), plot_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_network_clusters(g, lp_coms, pos, figsize=(20, 20), plot_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such strategy is feasible when the network is small enogh. In case of medium size graphs an alternative is collapsing all community nodes into a single met-node and visualize the resulting community graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_community_graph(g, louvain_coms, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_community_graph(g, lp_coms, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community fitness/comparison visualization\n",
    "\n",
    "Given one (or more) clustering it could be useful to visualize how a given fitness function distributes over the communities.\n",
    "\n",
    "A nice way to do so is by using violin plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_com_stat([louvain_coms, lp_coms], evaluation.internal_edge_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple visualization type that allows getting a few insights on community characteristics is the scatter plot.\n",
    "\n",
    "We can easily pair-wise compare fitness functions for one or more clustering as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_com_properties_relation([louvain_coms, lp_coms], evaluation.size, evaluation.internal_edge_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"qualitative\"></a>\n",
    "### Qualitative evaluation ([to top](#top))\n",
    "\n",
    "Another way to validate a clustering is to analyse the purity of each community w.r.t. an external attribute.\n",
    "\n",
    "In our example, let's consider the 'club' attributes: what's the CD approach among the tested ones that allows to identify more \"homogeneous\" clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_purities(coms, nth):\n",
    "    purities = []\n",
    "    for c in coms.communities:\n",
    "        houses = []\n",
    "        for node in c:\n",
    "            if node in nth:\n",
    "                houses.append(nth[node])\n",
    "        \n",
    "        cnt = Counter(houses)\n",
    "        purity = max(cnt.values())/sum(cnt.values())\n",
    "        purities.append(purity)\n",
    "    return purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = nx.get_node_attributes(g, 'club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain_purities = all_purities(louvain_coms, attrs)\n",
    "louvain_purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(louvain_purities), np.std(louvain_purities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_purities = all_purities(lp_coms, attrs)\n",
    "lp_purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(lp_purities), np.std(lp_purities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gt\"></a>\n",
    "### Ground Truth evaluation ([to top](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let assume we want to compare different clusterings over a set of network ground truth partitions.\n",
    "\n",
    "In order to obtain a more interesting example, we can generate a few synthetic graphs with planted ground truth clusterings and perform CD upon them. <br/> We can easily visually compare their resuls as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import NodeClustering\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "\n",
    "g1 = LFR_benchmark_graph(1000, 3, 1.5, 0.5, min_community=20, average_degree=5)\n",
    "g2 = LFR_benchmark_graph(1000, 3, 1.5, 0.6, min_community=20, average_degree=5)\n",
    "g3 = LFR_benchmark_graph(1000, 3, 1.5, 0.7, min_community=20, average_degree=5)\n",
    "\n",
    "names = [\"g1\", \"g2\", \"g3\"]\n",
    "graphs = [g1, g2, g3]\n",
    "references = []\n",
    "\n",
    "# building the NodeClustering ground truth for the graphs\n",
    "for g in graphs:\n",
    "    ground_truth = NodeClustering(communities={frozenset(g.nodes[v]['community']) for v in g}, graph=g, method_name=\"reference\")\n",
    "    references.append(ground_truth)\n",
    "    \n",
    "algos = [algorithms.louvain, algorithms.label_propagation]\n",
    "\n",
    "# Computing the visualization (2 execution per method, NMI as scoring for ground truth resemblance)\n",
    "viz.plot_scoring(graphs, references, names, algos, scoring=evaluation.adjusted_mutual_information, nbRuns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also compare different clustering obtained on the same graph by alternative algorithms among them. <br/>\n",
    "Let's get back to our initial Karate Club graph and compute a few more clusterings upon it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lp_coms = algorithms.label_propagation(g)\n",
    "louvain_coms = algorithms.louvain(g)\n",
    "wp_coms = algorithms.walktrap(g)\n",
    "\n",
    "viz.plot_sim_matrix([louvain_coms, lp_coms, wp_coms],evaluation.adjusted_mutual_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "# *Dynamic Community Discovery*\n",
    "\n",
    "In this notebook are introduced the main steps for the extraction and topological analysis of communities from dynamic networks.\n",
    "\n",
    "**Note:** this notebook is purposely not 100% comprehensive, it only discusses the basic things you need to get started. For all the details, algorithm/methods/evaluation facilities available in ``CDlib``, please refer to the official [documentation](https://cdlib.readthedocs.io) and the dedicated notebook appendix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import algorithms, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import TemporalClustering\n",
    "g1 = LFR_benchmark_graph(1000, 3, 1.5, 0.5, min_community=20, average_degree=5)\n",
    "g2 = LFR_benchmark_graph(1000, 3, 1.5, 0.6, min_community=20, average_degree=5)\n",
    "g3 = LFR_benchmark_graph(1000, 3, 1.5, 0.7, min_community=20, average_degree=5)\n",
    "\n",
    "names = [\"g1\", \"g2\", \"g3\"]\n",
    "graphs = [g1, g2, g3]\n",
    "tc = TemporalClustering()\n",
    "for t in range(3):  # Simulating a dynamic graph by cycling through the three graphs\n",
    "    g = graphs[t]  # In a real scenario, this would be a different graph\n",
    "    coms = algorithms.louvain(g)  # here any CDlib algorithm can be applied\n",
    "    tc.add_clustering(coms, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After built the temporal clustering it is possible to inspect the available temporal ids of the stored clusterings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.get_observation_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and use them to access individual clusterings (thus allowing standard analyses as discussed in Chapter 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.get_clustering_at(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple measure of temporal stability is the clustering stability trend.\n",
    "\n",
    "Given as input a TemporalClustering and a partition similarity score (e.g., NMI, NF1...) such a trend describe how much partitions tend to remain the same as time goes by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = tc.clustering_stability_trend(evaluation.nf1)\n",
    "trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our aim is to transform a static algorithm into a dinamic one, once computed the clusterings we have to match them across consecutive temporal ids.\n",
    "\n",
    "We can check that our custom made approach does not came an explicit matching with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.has_explicit_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we can use the <code>LifeCycle</code> object to compute events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib import LifeCycle\n",
    "lc = LifeCycle(tc)\n",
    "lc.compute_events() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the supported event types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.get_event_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = lc.get_event(\"1_2\") # to compute events for all communities use the get_events() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ev.out_flow)  # to get the out flow of the community 1_2\n",
    "print(ev.in_flow)  # to get the in flow of the community 1_2\n",
    "print(ev.from_event)  # to get the from events of the community 1_2\n",
    "print(ev.to_event)  # to get the to events of the community 1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_flow = lc.analyze_flow(\"1_2\", \"+\") # if the community id is not specified all the communities are considered\n",
    "in_flow = lc.analyze_flow(\"1_2\", \"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, if the temporal network comes with attributes associated to the nodes (either dynamically changing or not - i.e., political leanings), the library provides a set of tools to analyze the typicality of the events.\n",
    "\n",
    "Setting and retreiving node attributes is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_leaning():\n",
    "    \"\"\"Generates a random political leaning attribute for 250 nodes over 10 time steps.\"\"\"\n",
    "    attrs = {}\n",
    "    for i in range(250): # 250 nodes\n",
    "        attrs[i] = {}\n",
    "        for t in range(10): # 10 time steps\n",
    "            attrs[i][t] = random.choice([\"left\", \"right\"])\n",
    "    return attrs\n",
    "\n",
    "tc = TemporalClustering()\n",
    "for t in range(0, 10):\n",
    "    g = LFR_benchmark_graph(\n",
    "            n=250,\n",
    "            tau1=3,\n",
    "            tau2=1.5,\n",
    "            mu=0.1,\n",
    "            average_degree=5,\n",
    "            min_community=20,\n",
    "            seed=10,\n",
    "    )\n",
    "    coms = algorithms.louvain(g)  # here any CDlib algorithm can be applied\n",
    "    tc.add_clustering(coms, t)\n",
    "\n",
    "events = LifeCycle(tc)\n",
    "events.compute_events(\"facets\") # or \"greene\" or \"asur\"\n",
    "events.set_attribute(random_leaning(), \"political_leaning\")\n",
    "attrs = events.get_attribute(\"political_leaning\")\n",
    "\n",
    "events.analyze_flow(\"1_1\", \"+\",  attr=\"political_leaning\") # to analyze the flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library provides a set of tools to visualize the events and flows detected in the community structure of a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdlib.viz import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an example of how to visualize community events, flows and polytree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plot_flow(events)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_event_radar(events, \"1_2\", direction=\"+\") # only out events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_event_radars(events, \"1_2\") # both in and out events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = typicality_distribution(events, \"+\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = events.polytree()\n",
    "fig = nx.draw_networkx(dg, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Identifying echo chambers on reddit\n",
    "An echo chamber is commonly defined as a polarized situation in which beliefs are amplified or reinforced by communication repetition inside a closed system and insulated from rebuttal.\n",
    "\n",
    "In this exercise, we will adopt a methodology that leverages community detection and node attributes to identify echo chambers on reddit political discussions.\n",
    "\n",
    "The methodology is motivated and explained in detail in:\n",
    "\n",
    "Morini, V., Pollacci, L., & Rossetti, G. (2021). [Toward a standard approach for echo chamber detection: Reddit case study](https://www.mdpi.com/2076-3417/11/12/5390). Applied Sciences, 11(12), 5390."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's download the data. This downloads three files to your machine. Each of them is a snapshot of 6months of discussions about gun control on Reddit. Nodes are users connected if they discuss together. Each node is labeled as either 'protrump' or 'antitrump'. You can find this information by getting the 'discrete_leaning' via networkx's <code>nx.get_node_attribute()</code>.\n",
    "\n",
    "\n",
    "Files are named \"guncontrol-tX.gexf\", where X is a number in [0,1,2] that identifies a semester. All files are gexf-formatted. you can read them with <code>nx.read_gexf()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for t in 0 1 2; do\n",
    "  curl -L \"https://raw.githubusercontent.com/andreafailla/MBD-SNA-Lab/main/data/politics-t${t}.gexf\" \\\n",
    "       -o \"guncontrol-t${t}.gexf\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data in the cell below, in a variable called 'g'. Then, obtain the 'discrete_leaning' attribute for each node and store them in a variable called 'attrs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the EVA algorith, a modification of the Louvain that balances structure and community attribute purity. You can call it with <code>algorithms.eva(g, labels={'discrete_leaning': attrs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two functions that compute the conductance and purity. They take as inputs only the graph and the list of nodes representing the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_conductance(graph, community):\n",
    "    \"\"\"\n",
    "    Compute the conductance of a given community in a graph.\n",
    "\n",
    "    Parameters:\n",
    "    - graph: networkx.Graph\n",
    "    - community: list or set of node IDs\n",
    "\n",
    "    Returns:\n",
    "    - conductance: float\n",
    "    \"\"\"\n",
    "    community_set = set(community)\n",
    "    cut_edges = 0\n",
    "    volume = 0\n",
    "\n",
    "    for node in community_set:\n",
    "        for neighbor in graph.neighbors(node):\n",
    "            if neighbor not in community_set:\n",
    "                cut_edges += 1\n",
    "        volume += graph.degree(node)\n",
    "\n",
    "    if volume == 0 or volume == graph.size() * 2:\n",
    "        return 0.0\n",
    "\n",
    "    outside_volume = sum(dict(graph.degree()).values()) - volume\n",
    "    denom = min(volume, outside_volume)\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return cut_edges / denom\n",
    "\n",
    "def community_purity(g, community, attr_name):\n",
    "    \"\"\"\n",
    "    Compute the purity of a community based on a given attribute.\n",
    "\n",
    "    Parameters:\n",
    "    - g: networkx.Graph\n",
    "    - community: list or set of node IDs\n",
    "    - attr_name: name of the attribute to evaluate purity\n",
    "\n",
    "    Returns:\n",
    "    - purity: float\n",
    "    \"\"\"\n",
    "    community_set = set(community)\n",
    "    attr_values = [g.nodes[node][attr_name] for node in community_set if attr_name in g.nodes[node]]\n",
    "    \n",
    "    if not attr_values:\n",
    "        return 0.0\n",
    "    \n",
    "    most_common_value, count = Counter(attr_values).most_common(1)[0]\n",
    "    return count / len(attr_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each community, compute their purity and conductance. Then, print 'Echo chamber detected' if conductance < 0.5 and purity > 0.7. Otherwise print 'This is not an echo chamber!'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
